- Write more efficient way to compute bdiff 
  for entire batch separately or a subsample of it
  preferably in parallel
- Test whether non-generalization fenomena works
 the same for 1st order methods across diff. batch sizes and seq. sizes
  * if yes, try to isolate the issue. see if it's consequence of step rejection first
- Find good heuristics for preconditioning based on previous iteration ranges
- Possible preconditioners:
   . FIM diagonal for full or partial batch
   . FIM of previous batch
   . ADAM diagonal
- Generalize LinearRegressor to handle multiple outputs (like LogisticRegressor)

- Rewrite PCGOptimizer to use RegularizedModel(mdl)

- Separate Optimizers into mixins
  - First Order oracle vs Second Order oracle
  - Stochastic vs Deterministic vs Hybrid setting
    - Deterministic Thrust Region vs Line Search

- Hybrid Idea:
  - Fixed small TR steps and accumulate norm of each step instead of euclidean distance to previous point
  - This might work like an approximation of geodesic distance

-Architecture:
  - Composition for Optimizers:
    .step computer (has internal state: momentum, etc...)
    .globalizer (tr, lr, line search, etc...) (may interfere with step computer)
    .regularizer (l2, l1, l2 w.r.t. fixed point)